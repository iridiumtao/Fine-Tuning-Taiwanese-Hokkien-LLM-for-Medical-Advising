{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db769802-f654-47c4-980b-47424af9e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cafe83b-33c9-44c9-a7e0-e20476f15da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('DATA_DIR', 'data46')\n",
    "\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263ea89f-9c05-4482-9c70-c1272d311411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_path = os.path.join(data_dir, 'raw/medQA/train.jsonl')\n",
    "\n",
    "converted = []\n",
    "\n",
    "# Load and convert data \n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "        question = item.get(\"question\", \"\").strip()\n",
    "        options = item.get(\"options\", {})\n",
    "        answer_idx = item.get(\"answer_idx\", \"\").strip()\n",
    "        answer_text = item.get(\"answer\", \"\").strip()\n",
    "\n",
    "        if not question or not options or not answer_idx or not answer_text:\n",
    "            continue  # skip incomplete entries\n",
    "\n",
    "        # Convert options dict into A: xxx\\nB: xxx...\n",
    "        formatted_options = \"\\n\".join([f\"{k}: {v}\" for k, v in options.items()])\n",
    "        \n",
    "        # Format instruction\n",
    "        prompt = (\n",
    "            f\"你是一位專業的醫療諮詢助理。請根據下列問題及選項，用口語化的方式簡單回覆正確答案並說明理由。\\n\"\n",
    "            f\"Q: {question}\\n{formatted_options}\\n請選出正確答案並說明理由。\"\n",
    "            )\n",
    "\n",
    "        # Combine letter and answer text\n",
    "        answer_label = options.get(answer_idx, \"\").strip()\n",
    "        full_output = f\"A: {answer_label}。{answer_text} <END>\" #add <END> to prevent model to repeat the answer\n",
    "\n",
    "        converted.append({\n",
    "            \"instruction\": prompt,\n",
    "            \"input\": \"\",\n",
    "            \"output\": full_output\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf27389-d1bc-425c-9b75-75c524bdef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'train_formatted.jsonl'\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for item in converted:\n",
    "        outfile.write(json.dumps(item, ensure_ascii = False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f73ff-9701-49ae-905e-ff9d548e96d8",
   "metadata": {},
   "source": [
    "### load hokkien corpus from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf8f410-e397-4ab9-991e-20832bcdad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f572997f34c94362925a49030d6dc90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0c8ed2b36b478ea4c3ea2278758059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-080cdbb3423d2e7d.parquet:   0%|          | 0.00/75.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e18f824b1fc4eeea1dac669252a7b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6759dab50cc4f3ba62d7eb7d5e17e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4266c09d880415d98ad558f7046554b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/37.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb303c395d2e4a36b6b001da71eb0d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, get_dataset_config_names\n",
    "\n",
    "# Load ICorpus-100\n",
    "icorpus = load_dataset(\"BohanLu/ICorpus-100\")\n",
    "# Load TAIDE-14-tasks-Hokkien\n",
    "taide = load_dataset(\"BohanLu/TAIDE-14-tasks-Hokkien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf5bcf1-2912-4701-ab8b-07417a192d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available TAIDE-14 configs:\n",
      "- default\n",
      "ICorpus-100 splits: dict_keys(['test'])\n",
      "TAIDE-14-tasks-Hokkien splits: dict_keys(['train'])\n",
      "\n",
      "--- ICorpus-100 sample ---\n",
      "{'ID': 0, 'ZH': '還是在打麻將？', 'HAN': '猶是佇拍麻雀？', 'TL': 'iáu-sī-tī phah-muâ-tshiok？', 'EN': 'Are you still playing mahjong?', 'POJ': 'iáu-sī-tī phah-môa-chhiok？'}\n",
      "\n",
      "--- TAIDE-14-tasks-Hokkien sample ---\n",
      "{'Topic': '生物學和生物技術', 'Task': '分類', 'Keywords': '有什麼風險？', 'Prompt': '共下面的生物科技的應用分做三類：低風險、中風險佮高風險，閣簡單解說一下為啥物欲按呢分類？\\n基因編輯、生物染料、基因療法、基因工程作物、細胞再生、複製技術、人類胚胎研究、生物能源。'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "all_configs = get_dataset_config_names(\"BohanLu/TAIDE-14-tasks-Hokkien\")\n",
    "print(\"Available TAIDE-14 configs:\")\n",
    "for config in all_configs:\n",
    "    print(\"-\", config)\n",
    "\n",
    "# Print what splits exist\n",
    "print(\"ICorpus-100 splits:\", icorpus.keys())\n",
    "print(\"TAIDE-14-tasks-Hokkien splits:\", taide.keys())\n",
    "\n",
    "# Now try to print a sample\n",
    "print(\"\\n--- ICorpus-100 sample ---\")\n",
    "print(icorpus[\"test\"][0])\n",
    "\n",
    "print(\"\\n--- TAIDE-14-tasks-Hokkien sample ---\")\n",
    "print(taide[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fe79d1-9fdf-4ca3-9a38-217d4cc4b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f5d91b67bf443b8937240135c16d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edf42338be34993a9f29e86579437ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined dataset sample ---\n",
      "{'ID': None, 'ZH': None, 'HAN': None, 'TL': None, 'EN': None, 'POJ': None, 'text': '<|user|>\\n請問一个受著天氣變遷影響較大的所在，彼搭可能會面對的問題、遐的天氣變化的現象佮佇佗位會使揣著閣較濟的相關資訊。\\n<|assistant|>\\n<|endoftext|>', 'Topic': '環境和氣候變化', 'Task': '開放式生成', 'Keywords': '在哪裡？', 'Prompt': '請問一个受著天氣變遷影響較大的所在，彼搭可能會面對的問題、遐的天氣變化的現象佮佇佗位會使揣著閣較濟的相關資訊。'}\n"
     ]
    }
   ],
   "source": [
    "def format_icorpus(example):\n",
    "    return {\n",
    "        \"text\": f\"<|user|>\\n{example['HAN']}\\n<|assistant|>\\n{example['HAN']}<|endoftext|>\"\n",
    "    }\n",
    "\n",
    "def format_taide(example):\n",
    "    return {\n",
    "        \"text\": f\"<|user|>\\n{example['Prompt']}\\n<|assistant|>\\n<|endoftext|>\"\n",
    "    }\n",
    "\n",
    "\n",
    "# Map format\n",
    "formatted_icorpus = icorpus[\"test\"].map(format_icorpus)\n",
    "formatted_taide = taide[\"train\"].map(format_taide)\n",
    "\n",
    "# Combine\n",
    "combined_dataset = concatenate_datasets([formatted_icorpus, formatted_taide])\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_dataset = combined_dataset.shuffle(seed = 42)\n",
    "\n",
    "print(\"\\n--- Combined dataset sample ---\")\n",
    "print(combined_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c77aa39-5794-42f3-9c85-0ce0377713c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01be01831aad472d9bf866a566a98da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "256682"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the combined dataset for stage 2\n",
    "out_path = \"hokkien_pretrain_combined.jsonl\"\n",
    "combined_dataset.to_json(out_path, orient = \"records\", lines = True, force_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "221ab817-961a-4918-9e32-bea235e65622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading /home/jovyan/work/train_formatted.jsonl to chi_tacc:object-persist-project46/processed/train_formatted.jsonl...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 6.950 MiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.4s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 6.950 MiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.9s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t    6.950 MiB / 6.950 MiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.3s\n",
      "Upload command for train_formatted.jsonl executed.\n",
      "Uploading /home/jovyan/work/hokkien_pretrain_combined.jsonl to chi_tacc:object-persist-project46/processed/hokkien_pretrain_combined.jsonl...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 250.666 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.4s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 250.666 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.9s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t  250.666 KiB / 250.666 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.1s\n",
      "Upload command for hokkien_pretrain_combined.jsonl executed.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rclone_remote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m files_to_upload:\n\u001b[0;32m---> 22\u001b[0m     check_remote_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrclone_remote\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrclone_bucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/processed_notebook_outputs/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mChecking remote directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck_remote_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrclone ls \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck_remote_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rclone_remote' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_to_upload = [\"train_formatted.jsonl\", \"hokkien_pretrain_combined.jsonl\"]\n",
    "\n",
    "rclone_container = os.getenv(\"RCLONE_CONTAINER\")\n",
    "\n",
    "if not rclone_container:\n",
    "    print(\"ERROR: RCLONE_CONTAINER environment variables are not set.\")\n",
    "else:\n",
    "    for filename in files_to_upload:\n",
    "        local_file_path = f\"/home/jovyan/work/{filename}\"\n",
    "        remote_destination_path = f\"chi_tacc:{rclone_container}/processed/{filename}\"\n",
    "\n",
    "        if os.path.exists(local_file_path):\n",
    "            print(f\"Uploading {local_file_path} to {remote_destination_path}...\")\n",
    "            get_ipython().system(f'rclone copy \"{local_file_path}\" \"{remote_destination_path}\" --progress')\n",
    "            print(f\"Upload command for {filename} executed.\")\n",
    "        else:\n",
    "            print(f\"File not found: {local_file_path}\")\n",
    "\n",
    "    if files_to_upload:\n",
    "        check_remote_path = f\"chi_tacc:{rclone_container}/processed_notebook_outputs/\"\n",
    "        print(f\"\\nChecking remote directory: {check_remote_path}\")\n",
    "        get_ipython().system(f'rclone ls \"{check_remote_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0765f2-6876-4a2a-93a5-6473b536677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_formatted.jsonl removed.\n",
      "'hokkien_pretrain_combined.jsonl removed.\n"
     ]
    }
   ],
   "source": [
    "# remove files\n",
    "\n",
    "for file_path in files_to_upload:\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"'{file_path} removed.\")\n",
    "        except OSError as e:\n",
    "            print(f\"{e.strerror}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e54e1-5aac-4948-8aff-10554b80a4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
