{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db769802-f654-47c4-980b-47424af9e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a7095-9752-4ef6-b6ec-743006c665a4",
   "metadata": {},
   "source": [
    "### load MedQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cafe83b-33c9-44c9-a7e0-e20476f15da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models', 'raw']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('DATA_DIR', 'data46')\n",
    "\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263ea89f-9c05-4482-9c70-c1272d311411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processes_and_safe(input_path, output_path):\n",
    "\n",
    "    converted = []\n",
    "    # Load and convert data \n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            item = json.loads(line)\n",
    "            question = item.get(\"question\", \"\").strip()\n",
    "            options = item.get(\"options\", {})\n",
    "            answer_idx = item.get(\"answer_idx\", \"\").strip()\n",
    "            answer_text = item.get(\"answer\", \"\").strip()\n",
    "    \n",
    "            if not question or not options or not answer_idx or not answer_text:\n",
    "                continue  # skip incomplete entries\n",
    "    \n",
    "            # Convert options dict into A: xxx\\nB: xxx...\n",
    "            formatted_options = \"\\n\".join([f\"{k}: {v}\" for k, v in options.items()])\n",
    "            \n",
    "            # Format instruction\n",
    "            prompt = (\n",
    "                f\"你是一位專業的醫療諮詢助理。請根據下列問題及選項，用口語化的方式簡單回覆正確答案並說明理由。\\n\"\n",
    "                f\"Q: {question}\\n{formatted_options}\\n請選出正確答案並說明理由。\"\n",
    "                )\n",
    "    \n",
    "            # Combine letter and answer text\n",
    "            answer_label = options.get(answer_idx, \"\").strip()\n",
    "            full_output = f\"A: {answer_label}。{answer_text} <END>\" #add <END> to prevent model to repeat the answer\n",
    "    \n",
    "            converted.append({\n",
    "                \"instruction\": prompt,\n",
    "                \"input\": \"\",\n",
    "                \"output\": full_output\n",
    "            })\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for item in converted:\n",
    "            outfile.write(json.dumps(item, ensure_ascii = False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf27389-d1bc-425c-9b75-75c524bdef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "input_path = os.path.join(data_dir, 'raw/medQA/train.jsonl')\n",
    "output_path = 'train_formatted.jsonl'\n",
    "processes_and_safe(input_path, output_path)\n",
    "\n",
    "# test\n",
    "input_path = os.path.join(data_dir, 'raw/medQA/test.jsonl')\n",
    "output_path = 'test_formatted.jsonl'\n",
    "processes_and_safe(input_path, output_path)\n",
    "\n",
    "# dev\n",
    "input_path = os.path.join(data_dir, 'raw/medQA/dev.jsonl')\n",
    "output_path = 'dev_formatted.jsonl'\n",
    "processes_and_safe(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f73ff-9701-49ae-905e-ff9d548e96d8",
   "metadata": {},
   "source": [
    "### load hokkien corpus from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf8f410-e397-4ab9-991e-20832bcdad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c335fc79b5d42c08fb78d818d1dfd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af423d88fa0844d882da875c29ce39c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-080cdbb3423d2e7d.parquet:   0%|          | 0.00/75.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c66c5f1081c44698bea54acde578334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4970e9e75c2a4847aa72b3d279ab2f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e956574004402099d8d762d8e6f4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/37.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecdbe29c25542a8b78a0c0a20a3fc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, get_dataset_config_names\n",
    "\n",
    "# Load ICorpus-100\n",
    "icorpus = load_dataset(\"BohanLu/ICorpus-100\")\n",
    "# Load TAIDE-14-tasks-Hokkien\n",
    "taide = load_dataset(\"BohanLu/TAIDE-14-tasks-Hokkien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf5bcf1-2912-4701-ab8b-07417a192d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available TAIDE-14 configs:\n",
      "- default\n",
      "ICorpus-100 splits: dict_keys(['test'])\n",
      "TAIDE-14-tasks-Hokkien splits: dict_keys(['train'])\n",
      "\n",
      "--- ICorpus-100 sample ---\n",
      "{'ID': 0, 'ZH': '還是在打麻將？', 'HAN': '猶是佇拍麻雀？', 'TL': 'iáu-sī-tī phah-muâ-tshiok？', 'EN': 'Are you still playing mahjong?', 'POJ': 'iáu-sī-tī phah-môa-chhiok？'}\n",
      "\n",
      "--- TAIDE-14-tasks-Hokkien sample ---\n",
      "{'Topic': '生物學和生物技術', 'Task': '分類', 'Keywords': '有什麼風險？', 'Prompt': '共下面的生物科技的應用分做三類：低風險、中風險佮高風險，閣簡單解說一下為啥物欲按呢分類？\\n基因編輯、生物染料、基因療法、基因工程作物、細胞再生、複製技術、人類胚胎研究、生物能源。'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "all_configs = get_dataset_config_names(\"BohanLu/TAIDE-14-tasks-Hokkien\")\n",
    "print(\"Available TAIDE-14 configs:\")\n",
    "for config in all_configs:\n",
    "    print(\"-\", config)\n",
    "\n",
    "# Print what splits exist\n",
    "print(\"ICorpus-100 splits:\", icorpus.keys())\n",
    "print(\"TAIDE-14-tasks-Hokkien splits:\", taide.keys())\n",
    "\n",
    "# Now try to print a sample\n",
    "print(\"\\n--- ICorpus-100 sample ---\")\n",
    "print(icorpus[\"test\"][0])\n",
    "\n",
    "print(\"\\n--- TAIDE-14-tasks-Hokkien sample ---\")\n",
    "print(taide[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fe79d1-9fdf-4ca3-9a38-217d4cc4b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1e35d53fb94860ab7f7e4a085d0e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baf3504eae642db9a9808e435b5d164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_icorpus(example):\n",
    "    return {\n",
    "        \"text\": f\"<|user|>\\n{example['HAN']}\\n<|assistant|>\\n{example['HAN']}<|endoftext|>\"\n",
    "    }\n",
    "\n",
    "def format_taide(example):\n",
    "    return {\n",
    "        \"text\": f\"<|user|>\\n{example['Prompt']}\\n<|assistant|>\\n<|endoftext|>\"\n",
    "    }\n",
    "\n",
    "\n",
    "# Map format\n",
    "formatted_taide = taide[\"train\"].map(format_taide)\n",
    "formatted_icorpus = icorpus[\"test\"].map(format_icorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c77aa39-5794-42f3-9c85-0ce0377713c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b011f17aadf4a22aaa793d08b15ea69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db449dd198e24f01889b04de59a64077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "130847"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save dataset for stage 2\n",
    "\n",
    "out_path = \"hokkien_pretrain_train.jsonl\"\n",
    "formatted_taide.to_json(out_path, orient = \"records\", lines = True, force_ascii = False)\n",
    "\n",
    "out_path = \"hokkien_pretrain_test.jsonl\"\n",
    "formatted_icorpus.to_json(out_path, orient = \"records\", lines = True, force_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221ab817-961a-4918-9e32-bea235e65622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading /home/jovyan/work/train_formatted.jsonl to chi_tacc:object-persist-project46/processed...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 6.950 MiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.3s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 6.950 MiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.8s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t    6.950 MiB / 6.950 MiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.1s\n",
      "Upload command for train_formatted.jsonl executed.\n",
      "Uploading /home/jovyan/work/test_formatted.jsonl to chi_tacc:object-persist-project46/processed...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 901.610 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.3s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 901.610 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.8s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t  901.610 KiB / 901.610 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "Upload command for test_formatted.jsonl executed.\n",
      "Uploading /home/jovyan/work/dev_formatted.jsonl to chi_tacc:object-persist-project46/processed...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 892.299 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.3s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 892.299 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.8s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t  892.299 KiB / 892.299 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "Upload command for dev_formatted.jsonl executed.\n",
      "Uploading /home/jovyan/work/hokkien_pretrain_train.jsonl to chi_tacc:object-persist-project46/processed...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 108.843 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.3s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 108.843 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.8s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t  108.843 KiB / 108.843 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "Upload command for hokkien_pretrain_train.jsonl executed.\n",
      "Uploading /home/jovyan/work/hokkien_pretrain_test.jsonl to chi_tacc:object-persist-project46/processed...\n",
      "\u001b[2K\u001b[1GTransferred:   \t          0 B / 127.780 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.3s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t          0 B / 127.780 KiB, 0%, 0 B/s, ETA -\n",
      "Transferred:            0 / 1, 0%\n",
      "Elapsed time:         0.8s\n",
      "Transferring:\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1GTransferred:   \t  127.780 KiB / 127.780 KiB, 100%, 0 B/s, ETA -\n",
      "Transferred:            1 / 1, 100%\n",
      "Elapsed time:         1.0s\n",
      "Upload command for hokkien_pretrain_test.jsonl executed.\n",
      "\n",
      "Checking remote directory: chi_tacc:object-persist-project46/processed_notebook_outputs/\n"
     ]
    }
   ],
   "source": [
    "files_to_upload = [\"train_formatted.jsonl\", \"test_formatted.jsonl\",\"dev_formatted.jsonl\", \"hokkien_pretrain_train.jsonl\", \"hokkien_pretrain_test.jsonl\"]\n",
    "\n",
    "rclone_container = \"object-persist-project46\"\n",
    "\n",
    "if not rclone_container:\n",
    "    print(\"ERROR: RCLONE_CONTAINER environment variables are not set.\")\n",
    "else:\n",
    "    for filename in files_to_upload:\n",
    "        local_file_path = f\"/home/jovyan/work/{filename}\"\n",
    "        remote_destination_path = f\"chi_tacc:{rclone_container}/processed\"\n",
    "\n",
    "        if os.path.exists(local_file_path):\n",
    "            print(f\"Uploading {local_file_path} to {remote_destination_path}...\")\n",
    "            get_ipython().system(f'rclone copy \"{local_file_path}\" \"{remote_destination_path}\" --progress')\n",
    "            print(f\"Upload command for {filename} executed.\")\n",
    "        else:\n",
    "            print(f\"File not found: {local_file_path}\")\n",
    "\n",
    "    if files_to_upload:\n",
    "        check_remote_path = f\"chi_tacc:{rclone_container}/processed_notebook_outputs/\"\n",
    "        print(f\"\\nChecking remote directory: {check_remote_path}\")\n",
    "        get_ipython().system(f'rclone ls \"{check_remote_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac0765f2-6876-4a2a-93a5-6473b536677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_formatted.jsonl removed.\n",
      "'test_formatted.jsonl removed.\n",
      "'dev_formatted.jsonl removed.\n",
      "'hokkien_pretrain_train.jsonl removed.\n",
      "'hokkien_pretrain_test.jsonl removed.\n"
     ]
    }
   ],
   "source": [
    "# remove files\n",
    "\n",
    "for file_path in files_to_upload:\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"'{file_path} removed.\")\n",
    "        except OSError as e:\n",
    "            print(f\"{e.strerror}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e54e1-5aac-4948-8aff-10554b80a4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
